#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIåŠ©æ‰‹é¢æ¿ä¸»æ§åˆ¶å™¨
ä¸ºMarsæ—¥å¿—åˆ†æå™¨æä¾›AIè¾…åŠ©åˆ†æåŠŸèƒ½
"""

import threading
import tkinter as tk
from datetime import datetime
from tkinter import messagebox, ttk
from typing import Optional


def safe_import_ai_diagnosis():
    """å®‰å…¨å¯¼å…¥AIè¯Šæ–­æ¨¡å—"""
    try:
        from ai_diagnosis import AIClientFactory, AIConfig
        from ai_diagnosis.log_preprocessor import LogPreprocessor
        from ai_diagnosis.prompt_templates import PromptTemplates
        from ai_diagnosis.token_optimizer import TokenOptimizer
        return AIClientFactory, AIConfig, LogPreprocessor, PromptTemplates, TokenOptimizer
    except ImportError:
        try:
            from modules.ai_diagnosis import AIClientFactory, AIConfig
            from modules.ai_diagnosis.log_preprocessor import LogPreprocessor
            from modules.ai_diagnosis.prompt_templates import PromptTemplates
            from modules.ai_diagnosis.token_optimizer import TokenOptimizer
            return AIClientFactory, AIConfig, LogPreprocessor, PromptTemplates, TokenOptimizer
        except ImportError:
            from gui.modules.ai_diagnosis import AIClientFactory, AIConfig
            from gui.modules.ai_diagnosis.log_preprocessor import LogPreprocessor
            from gui.modules.ai_diagnosis.prompt_templates import PromptTemplates
            from gui.modules.ai_diagnosis.token_optimizer import TokenOptimizer
            return AIClientFactory, AIConfig, LogPreprocessor, PromptTemplates, TokenOptimizer


class AIAssistantPanel:
    """AIåŠ©æ‰‹é¢æ¿ä¸»æ§åˆ¶å™¨"""

    def __init__(self, parent, main_app):
        """
        åˆå§‹åŒ–AIåŠ©æ‰‹é¢æ¿

        Args:
            parent: çˆ¶å®¹å™¨
            main_app: ä¸»åº”ç”¨ç¨‹åºå®ä¾‹
        """
        self.parent = parent
        self.main_app = main_app

        # å¯¹è¯å†å²
        self.chat_history = []

        # æ˜¯å¦æ­£åœ¨å¤„ç†AIè¯·æ±‚
        self.is_processing = False

        # åœæ­¢æ ‡å¿—
        self.stop_flag = False

        # Tokenç´¯è®¡ç»Ÿè®¡
        self.total_input_tokens = 0
        self.total_output_tokens = 0

        # AIå®¢æˆ·ç«¯ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._ai_client = None

        # Tokenä¼˜åŒ–å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._token_optimizer = None

        # è¯„åˆ†è®°å½•ï¼ˆç”¨äºæ”¶é›†ç”¨æˆ·åé¦ˆï¼‰
        self.ratings = []

        # UIç»„ä»¶ï¼ˆåœ¨create_widgetsä¸­åˆå§‹åŒ–ï¼‰
        self.frame = None
        self.toolbar = None
        self.chat_panel = None
        self.navigation = None
        self.prompt_panel = None
        self.status_var = None
        self.stop_button = None
        self.progress = None

        # åˆ›å»ºUI
        self.create_widgets()

    @property
    def ai_client(self):
        """å»¶è¿Ÿåˆå§‹åŒ–AIå®¢æˆ·ç«¯ï¼ˆä»…ä½¿ç”¨Claude Codeï¼‰"""
        if self._ai_client is None:
            try:
                AIClientFactory, AIConfig, _, _, _ = safe_import_ai_diagnosis()

                # å›ºå®šä½¿ç”¨Claude Code
                self._ai_client = AIClientFactory.create(service='ClaudeCode')
            except Exception as e:
                messagebox.showerror(
                    "Claude Codeåˆå§‹åŒ–å¤±è´¥",
                    f"æ— æ³•è¿æ¥åˆ°Claude Code:\n{str(e)}\n\n"
                    f"è¯·ç¡®ä¿Claude Codeæ­£åœ¨è¿è¡Œã€‚"
                )
                return None
        return self._ai_client

    @property
    def token_optimizer(self):
        """å»¶è¿Ÿåˆå§‹åŒ–Tokenä¼˜åŒ–å™¨"""
        if self._token_optimizer is None:
            try:
                _, AIConfig, _, _, TokenOptimizer = safe_import_ai_diagnosis()
                config = AIConfig.load()
                model = config.get('model', 'claude-3-5-sonnet-20241022')
                self._token_optimizer = TokenOptimizer(model=model)
            except Exception as e:
                print(f"Tokenä¼˜åŒ–å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                # ä½¿ç”¨é»˜è®¤é…ç½®
                try:
                    _, _, _, _, TokenOptimizer = safe_import_ai_diagnosis()
                    self._token_optimizer = TokenOptimizer()
                except:
                    return None
        return self._token_optimizer

    def create_widgets(self):
        """åˆ›å»ºå¹¶ç»„è£…UIç»„ä»¶"""
        from .ui.toolbar_panel import ToolbarPanel
        from .ui.chat_panel import ChatPanel
        from .ui.navigation_helper import NavigationHelper
        from .ui.prompt_panel import PromptPanel

        self.frame = ttk.Frame(self.parent)
        self.frame.pack(fill=tk.BOTH, expand=True)

        # å…ˆåˆ›å»ºè¾…åŠ©ç»„ä»¶ï¼ˆä¸ä¾èµ–UIçš„ï¼‰
        self.navigation = NavigationHelper(self)
        self.prompt_panel = PromptPanel(self)

        # åˆ›å»ºèŠå¤©é¢æ¿
        self.chat_panel = ChatPanel(self.frame, self)
        self.chat_panel.pack(fill=tk.BOTH, expand=True, pady=(0, 5))

        # æœ€ååˆ›å»ºå·¥å…·æ ï¼ˆä¾èµ–chat_panelå’Œnavigationï¼‰
        self.toolbar = ToolbarPanel(self.frame, self)
        self.toolbar.pack(fill=tk.X, before=self.chat_panel)

        # çŠ¶æ€æ å’Œåœæ­¢æŒ‰é’®
        status_frame = ttk.Frame(self.frame)
        status_frame.pack(fill=tk.X, pady=(5, 0))

        self.status_var = tk.StringVar(value="å°±ç»ª")
        status_label = ttk.Label(
            status_frame,
            textvariable=self.status_var,
            font=("Arial", 9),
            foreground="#666666"
        )
        status_label.pack(side=tk.LEFT, expand=True)

        # åœæ­¢æŒ‰é’®ï¼ˆåˆå§‹éšè—ï¼‰
        self.stop_button = ttk.Button(
            status_frame,
            text="â¹ï¸ åœæ­¢",
            width=8,
            command=self.stop_processing
        )

        # è¿›åº¦æ¡ï¼ˆåˆå§‹éšè—ï¼‰
        self.progress = ttk.Progressbar(
            self.frame,
            mode='indeterminate',
            length=200
        )

    def set_status(self, message: str):
        """è®¾ç½®çŠ¶æ€æ–‡æœ¬"""
        self.status_var.set(message)

    def show_stop_button(self):
        """æ˜¾ç¤ºåœæ­¢æŒ‰é’®"""
        self.stop_button.pack(side=tk.RIGHT, padx=5)

    def hide_stop_button(self):
        """éšè—åœæ­¢æŒ‰é’®"""
        self.stop_button.pack_forget()

    def show_progress(self):
        """æ˜¾ç¤ºè¿›åº¦æ¡å¹¶å¼€å§‹æ»šåŠ¨åŠ¨ç”»"""
        self.progress.pack(fill=tk.X, pady=(2, 0))
        self.progress.start(10)  # 10msé—´éš”çš„æ»šåŠ¨åŠ¨ç”»

    def hide_progress(self):
        """éšè—è¿›åº¦æ¡å¹¶åœæ­¢åŠ¨ç”»"""
        self.progress.stop()
        self.progress.pack_forget()

    def stop_processing(self):
        """åœæ­¢AIå¤„ç†"""
        self.stop_flag = True
        self.set_status("æ­£åœ¨å–æ¶ˆ...")
        self.chat_panel.append_chat("system", "ç”¨æˆ·å·²å–æ¶ˆæ“ä½œ")

    def show_prompt_selector(self):
        """æ˜¾ç¤ºPrompté€‰æ‹©å™¨ï¼ˆå§”æ‰˜ç»™PromptPanelï¼‰"""
        self.prompt_panel.show_selector()

    def use_custom_prompt(self, prompt_id: str, context_log: Optional[str] = None):
        """ä½¿ç”¨è‡ªå®šä¹‰Promptï¼ˆå§”æ‰˜ç»™PromptPanelï¼‰"""
        self.prompt_panel.use_prompt(prompt_id, context_log)

    def get_context_params(self):
        """
        è·å–å½“å‰ä¸Šä¸‹æ–‡å‚æ•°é…ç½®

        Returns:
            æ ¹æ®context_sizeè¿”å›å¯¹åº”çš„å‚æ•°å­—å…¸
        """
        # ä¸Šä¸‹æ–‡å‚æ•°æ˜ å°„
        CONTEXT_PARAMS = {
            'ç®€åŒ–': {
                'crash_before': 10, 'crash_after': 5,
                'perf_logs': 50,
                'error_patterns': 5,
                'search_logs': 500, 'search_tokens': 4000
            },
            'æ ‡å‡†': {
                'crash_before': 20, 'crash_after': 10,
                'perf_logs': 100,
                'error_patterns': 10,
                'search_logs': 1000, 'search_tokens': 8000
            },
            'è¯¦ç»†': {
                'crash_before': 40, 'crash_after': 20,
                'perf_logs': 200,
                'error_patterns': 20,
                'search_logs': 2000, 'search_tokens': 16000
            }
        }

        _, AIConfig, _, _, _ = safe_import_ai_diagnosis()
        config = AIConfig.load()
        context_size = config.get('context_size', 'æ ‡å‡†')
        return CONTEXT_PARAMS.get(context_size, CONTEXT_PARAMS['æ ‡å‡†'])

    def ask_question(self):
        """è‡ªç”±æé—®"""
        question = self.chat_panel.question_var.get().strip()
        if not question:
            return

        # æ¸…ç©ºè¾“å…¥æ¡†
        self.chat_panel.question_var.set("")

        if self.is_processing:
            messagebox.showinfo("æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™")
            return

        self.is_processing = True
        self.stop_flag = False
        self.set_status("æ­£åœ¨æ€è€ƒ...")
        self.chat_panel.append_chat("user", question)
        self.main_app.root.after(0, self.show_stop_button)
        self.main_app.root.after(0, self.show_progress)

        def _ask():
            try:
                if self.stop_flag:
                    return
                # åŠ è½½é…ç½®
                _, AIConfig, LogPreprocessor, PromptTemplates, _ = safe_import_ai_diagnosis()
                config = AIConfig.load()
                context_size = config.get('context_size', 'æ ‡å‡†')
                show_token_usage = config.get('show_token_usage', True)

                # æ£€æŸ¥æ˜¯å¦æœ‰æ—¥å¿—
                has_logs = hasattr(self.main_app, 'log_entries') and self.main_app.log_entries

                # ç®€å•é—®å€™æˆ–æ²¡æœ‰æ—¥å¿—æ—¶ï¼Œä½¿ç”¨ç®€åŒ–æç¤ºè¯
                simple_greetings = ['ä½ å¥½', 'hello', 'hi', 'å—¨', 'æ‚¨å¥½']
                is_greeting = question.lower().strip() in simple_greetings

                if is_greeting or not has_logs:
                    # ç®€åŒ–æ¨¡å¼ï¼šä¸åŒ…å«æ—¥å¿—ä¸Šä¸‹æ–‡
                    prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{question}\n\n"
                    if not has_logs:
                        prompt += "æ³¨æ„ï¼šç”¨æˆ·è¿˜æ²¡æœ‰åŠ è½½æ—¥å¿—æ–‡ä»¶ã€‚"
                    else:
                        prompt += "è¿™æ˜¯ä¸€ä¸ªç®€å•çš„é—®å€™ï¼Œè¯·å‹å¥½åœ°å›å¤å¹¶ç®€è¦ä»‹ç»ä½ å¯ä»¥æä¾›çš„å¸®åŠ©ã€‚"

                    # ä¼°ç®—tokenæ•°ï¼ˆç²—ç•¥ä¼°è®¡ï¼šä¸­æ–‡1å­—=1tokenï¼Œè‹±æ–‡4å­—ç¬¦=1tokenï¼‰
                    estimated_tokens = len(prompt.replace(' ', '')) + len(prompt.split()) // 4
                else:
                    # å®Œæ•´æ¨¡å¼ï¼šä½¿ç”¨Tokenä¼˜åŒ–å™¨
                    optimizer = self.token_optimizer
                    if not optimizer:
                        self.main_app.root.after(0, self.chat_panel.append_chat, "system", "Tokenä¼˜åŒ–å™¨åˆå§‹åŒ–å¤±è´¥")
                        return

                    # è·å–å½“å‰æ—¥å¿—
                    current_logs = self.main_app.filtered_entries if hasattr(self.main_app, 'filtered_entries') and self.main_app.filtered_entries else self.main_app.log_entries

                    # ä¼˜åŒ–äº¤äº’å¼é—®ç­”æç¤ºè¯
                    optimized = optimizer.optimize_for_interactive_qa(
                        current_logs,
                        user_question=question
                    )

                    # æ£€æŸ¥tokené¢„ç®—
                    within_budget, message = optimizer.check_budget(optimized.estimated_tokens)
                    if not within_budget:
                        self.main_app.root.after(0, self.chat_panel.append_chat, "system", f"âš ï¸ {message}")
                        return

                    # æ˜¾ç¤ºtokenä½¿ç”¨æƒ…å†µï¼ˆä¼˜åŒ–åï¼‰
                    if show_token_usage:
                        self.main_app.root.after(0, self.set_status, f"ğŸ“Š {message} | å‹ç¼©æ¯”: {optimized.compression_ratio:.1%}")

                    # ä½¿ç”¨ä¼˜åŒ–åçš„æç¤ºè¯
                    prompt = optimized.prompt
                    estimated_tokens = optimized.estimated_tokens

                # æ˜¾ç¤ºtokenä½¿ç”¨æƒ…å†µï¼ˆä»…ç®€åŒ–æ¨¡å¼éœ€è¦ï¼Œå®Œæ•´æ¨¡å¼å·²åœ¨ä¸Šé¢æ˜¾ç¤ºï¼‰
                if (is_greeting or not has_logs) and show_token_usage:
                    token_info = f"ğŸ“Š Tokenä½¿ç”¨: è¾“å…¥~{estimated_tokens}"
                    self.main_app.root.after(0, self.set_status, token_info)

                # è°ƒç”¨AI
                if not self.ai_client:
                    self.main_app.root.after(0, self.chat_panel.append_chat, "system", "AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥")
                    return

                response = self.ai_client.ask(prompt)

                # ä¼°ç®—å“åº”tokenæ•°
                response_tokens = len(response.replace(' ', '')) + len(response.split()) // 4
                total_tokens = estimated_tokens + response_tokens

                # ç´¯åŠ Tokenç»Ÿè®¡
                self.total_input_tokens += estimated_tokens
                self.total_output_tokens += response_tokens

                # æ˜¾ç¤ºç»“æœ
                self.main_app.root.after(0, self.chat_panel.append_chat, "assistant", response)

                # æ›´æ–°tokenç»Ÿè®¡
                if show_token_usage:
                    session_total = self.total_input_tokens + self.total_output_tokens
                    token_summary = (
                        f"ğŸ“Š æœ¬æ¬¡: è¾“å…¥~{estimated_tokens} + è¾“å‡º~{response_tokens} = {total_tokens} | "
                        f"ä¼šè¯: è¾“å…¥~{self.total_input_tokens} + è¾“å‡º~{self.total_output_tokens} = {session_total}"
                    )
                    self.main_app.root.after(0, self.set_status, token_summary)

            except Exception as e:
                error_msg = f"æé—®å¤±è´¥: {str(e)}"
                self.main_app.root.after(0, self.chat_panel.append_chat, "system", error_msg)

            finally:
                self.is_processing = False
                self.main_app.root.after(0, self.hide_stop_button)
                self.main_app.root.after(0, self.hide_progress)
                # ä¸è¦†ç›–tokenç»Ÿè®¡ï¼Œå»¶è¿Ÿ3ç§’åæ¢å¤"å°±ç»ª"çŠ¶æ€
                if not show_token_usage or 'error_msg' in locals():
                    self.main_app.root.after(0, self.set_status, "å°±ç»ª")
                else:
                    self.main_app.root.after(3000, self.set_status, "å°±ç»ª")

        threading.Thread(target=_ask, daemon=True).start()
